{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e80ffc15",
   "metadata": {},
   "source": [
    "# Proposal Review Playground\n",
    "\n",
    "This notebook is for experimenting with the proposal review pipeline.\n",
    "You can use this to test different parts of the LLM feedback generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory to sys.path to import the proposal_reviewer module\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "\n",
    "from proposal_reviewer.reviewer import ProposalReviewer\n",
    "from prompts.abstract import ABSTRACT_PROMPT\n",
    "from prompts.general_writing import GENERAL_WRITING_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your OpenAI API key\n",
    "# Option 1: Set it directly in this notebook\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Option 2: Load from .env file\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# Initialize the reviewer\n",
    "reviewer = ProposalReviewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b80e5",
   "metadata": {},
   "source": [
    "## Extract Text from PDF\n",
    "\n",
    "The cell below processes a PDF file and extracts its text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ca521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your proposal PDF\n",
    "pdf_path = \"../input/proposal.pdf\"  # Update this path as needed\n",
    "\n",
    "# Extract text from PDF\n",
    "proposal_text = reviewer.extract_text_from_pdf(pdf_path)\n",
    "print(f\"Extracted {len(proposal_text)} characters from the PDF.\")\n",
    "\n",
    "# Display first 500 characters to verify extraction\n",
    "print(\"\\nFirst 500 characters:\")\n",
    "print(proposal_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac4476",
   "metadata": {},
   "source": [
    "## Extract the Abstract\n",
    "\n",
    "The cell below attempts to extract the abstract section from the proposal text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract abstract\n",
    "abstract_text = reviewer.extract_abstract(proposal_text)\n",
    "\n",
    "print(f\"Extracted abstract with {len(abstract_text)} characters.\")\n",
    "print(\"\\nAbstract:\")\n",
    "print(abstract_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2847f",
   "metadata": {},
   "source": [
    "## Generate Abstract Feedback\n",
    "\n",
    "The cell below sends the proposal text to the LLM to get feedback on the abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate abstract feedback\n",
    "abstract_feedback = reviewer.generate_abstract_feedback(proposal_text)\n",
    "\n",
    "print(\"\\nAbstract Feedback:\")\n",
    "print(abstract_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af7085",
   "metadata": {},
   "source": [
    "## Generate Writing Quality Feedback\n",
    "\n",
    "The cell below sends the extracted abstract to the LLM to get feedback on the writing quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate writing quality feedback\n",
    "writing_quality_feedback = reviewer.generate_writing_quality_feedback(abstract_text)\n",
    "\n",
    "print(\"\\nWriting Quality Feedback:\")\n",
    "print(writing_quality_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec0c8d",
   "metadata": {},
   "source": [
    "## Run Full Proposal Review\n",
    "\n",
    "The cell below runs the complete proposal review process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e95aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full review process\n",
    "feedback = reviewer.review_proposal(pdf_path)\n",
    "\n",
    "print(\"\\n=== Abstract Feedback ===\\n\")\n",
    "print(feedback[\"abstract_feedback\"])\n",
    "print(\"\\n=== Writing Quality Feedback ===\\n\")\n",
    "print(feedback[\"writing_quality_feedback\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddaafa1",
   "metadata": {},
   "source": [
    "## Experiment with Custom Prompts\n",
    "\n",
    "Feel free to modify the prompts below to experiment with different feedback styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f27bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
